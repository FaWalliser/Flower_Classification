Experimental unit -> Training run (1)

Experimental error -> Sources of randomness causing variability in results

Experimental subject -> Person who runs the Experiment

Contextual variables -> Variables with constant value in the Experiment

Response variable -> Performance measure of DNN

Factors -> Hyperparameters to be adjusted (Batch size (64, 32), learning rate (0.3, 0.5, 0.7), dropout (Yes, No), num. epochs, num. layers (only between 2 and 3 for the experiments))

Levels of factors -> Values for each factor

Interactions: Factors can interact so that one value for example is better depending on the other factor (cross) and if not, it is always better independent of the other factor (two parallel lines).

# Factors -> 2-3

# Levels -> 2-3

# Runs -> ? (12)

Randomization: Randomize the order within the sets of Runs (Comb 1, Comb 2, Comb 3, Comb 4 - randomize the order of runs between them)

Draft of the submission:
Design and analysis of at least a few runs
12 runs (at least 9)
Measurement scales - three types
ordinal scales: median
nominal: mode
third thing: mean (use this and only this)

All Measures of Dispersion:
Variance, standard distribution...

Scatter Block per Hyperparameter: y-Achse Performance, x-Achse Parameter (Learning rate, Batch size, Dropout)

Inferental Statistics: IBM SPSS - moodle tutorial, or python or R
Statistical significance of factors (forget about Intercept and that above)

Important: lack of homogenity of variances => stop at this point, we have to fix that for the final submission
